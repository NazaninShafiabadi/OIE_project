{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnb-lQgP6sQi"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "expected tuple format:\n",
        "\n",
        "t = {'arg1': [arg1 split into words],\n",
        "     'rel': [rel split into words],\n",
        "     'arg2': [arg2 split into words],\n",
        "     ...}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6jvYPOzDD5O"
      },
      "outputs": [],
      "source": [
        "def match_score(g, p):\n",
        "  \"\"\"\n",
        "  Input: a gold tuple g and a predicted tuple p\n",
        "  Output: the match score between g and p\n",
        "\n",
        "  (A side-effect of this scoring method:\n",
        "  If the system has correctly identified a piece of information but has not\n",
        "  put the words in the correct arguments of the extracted tuple, those\n",
        "  misplaced words will not be considered for the score)\n",
        "  \"\"\"\n",
        "  score = 0\n",
        "\n",
        "  # Looping through each part in g and p\n",
        "  for part in ['arg1', 'rel', 'arg2', 'arg3', 'arg4', 'arg5']:\n",
        "      # Checking if the part exists in both tuples\n",
        "      if part in g.keys() and part in p.keys():\n",
        "          # Computing the overlap of the tokens in the part of g and p\n",
        "          overlap = len(set(g[part]).intersection(set(p[part])))\n",
        "          # Updating the score by adding the overlap\n",
        "          score += overlap\n",
        "\n",
        "  # Normalizing the score by dividing by the total number of tokens in g and p\n",
        "  g_len = sum(len(arg) for arg in g.values())\n",
        "  p_len = sum(len(arg) for arg in p.values())\n",
        "  score /= (g_len + p_len)\n",
        "\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR_5YLHYDZdH"
      },
      "outputs": [],
      "source": [
        "def find_best_match(g, P):\n",
        "  \"\"\"\n",
        "  Input: a gold tuple g and a list of predicted tuples P\n",
        "  Output: the predicted tuple p_best in P that best matches g\n",
        "  \"\"\"\n",
        "  best_score = 0\n",
        "  p_best = None\n",
        "\n",
        "  # Looping through each predicted tuple in P\n",
        "  for p in P:\n",
        "      score = match_score(g, p)\n",
        "      if score > best_score:\n",
        "          best_score = score\n",
        "          p_best = p\n",
        "\n",
        "  return p_best, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNZUtov4GXqh"
      },
      "outputs": [],
      "source": [
        "def match(G, P):\n",
        "  \"\"\"\n",
        "  Input: a list of gold tuples G and a list of predicted tuples P\n",
        "  Output: a list of matching pairs M, and the lists of unmatched gold tuples UG and unmatched predicted tuples UP\n",
        "  \"\"\"\n",
        "  M = []\n",
        "  UG = []\n",
        "  UP = []\n",
        "\n",
        "  # Looping through each gold tuple in G\n",
        "  for g in G:\n",
        "      # Finding the tuple in the predicted tuples P that best matches g\n",
        "      p_best, score = find_best_match(g, P)\n",
        "\n",
        "      if p_best and score > threshold:\n",
        "          M.append((g, p_best))\n",
        "          P.remove(p_best)\n",
        "      else:\n",
        "          UG.append(g)\n",
        "\n",
        "  # Adding the remaining tuples in P to UP\n",
        "  UP = P\n",
        "\n",
        "  return M, UG, UP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hLWVNgOjVfO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe2YOTPDAL68"
      },
      "outputs": [],
      "source": [
        "def precision_sys(matching_pairs, unmatched_predictions):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    - matching_pairs: a list of pairs of matching gold and predicted tuples\n",
        "    - unmatched_predictions: a list of prediction tuples not found in the reference\n",
        "\n",
        "    Output: full system precision of predicted and reference tuples at the token level\n",
        "    (precision: the proportion of extracted words that are found in the reference)\n",
        "    \"\"\"\n",
        "    numerator = 0\n",
        "    denominator = 0\n",
        "\n",
        "    for (gold, pred) in matching_pairs:\n",
        "        pred_args = pred.keys()\n",
        "        # Summing the length of the intersection between matching predicted and gold tuples and adding the value to the precision numerator\n",
        "        numerator += sum(len(set(pred[arg]) & set(gold[arg])) for arg in pred_args)\n",
        "\n",
        "    _, matched_predictions = zip(*matching_pairs)\n",
        "    all_predictions = list(matched_predictions) + unmatched_predictions\n",
        "\n",
        "    for pred in all_predictions:\n",
        "        pred_args = pred.keys()\n",
        "        # Summing the lengths of all prediction tuples\n",
        "        denominator += sum(len(pred[arg]) for arg in pred_args)\n",
        "\n",
        "    try:\n",
        "        precision_sys = numerator / denominator\n",
        "    except ZeroDivisionError:\n",
        "        precision_sys = 0\n",
        "\n",
        "    return precision_sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm7k2GzDDUrX"
      },
      "outputs": [],
      "source": [
        "def recall_sys(matching_pairs, unmatched_references):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    - matching_pairs: a list of pairs of matching gold and predicted tuples\n",
        "    - unmatched_references: a list of reference tuples not found in the predictions\n",
        "\n",
        "    Output: full system recall of predicted and reference tuples at the token level\n",
        "    (recall: the proportion of reference words found in the systems’ predictions)\n",
        "    \"\"\"\n",
        "    numerator = 0\n",
        "    denominator = 0\n",
        "\n",
        "    for (gold, pred) in matching_pairs:\n",
        "        gold_args = gold.keys()\n",
        "        # Summing the length of the intersection between matching predicted and gold tuples and adding the value to the recall numerator\n",
        "        numerator += sum(len(set(pred[arg]) & set(gold[arg])) for arg in gold_args)\n",
        "\n",
        "    matched_references, _ = zip(*matching_pairs)\n",
        "    all_references = list(matched_references) + unmatched_references\n",
        "\n",
        "    for gold in all_references:\n",
        "        gold_args = gold.keys()\n",
        "        # Summing the lengths of all reference tuples\n",
        "        denominator += sum(len(gold[arg]) for arg in gold_args)\n",
        "\n",
        "    try:\n",
        "        recall_sys = numerator / denominator\n",
        "    except ZeroDivisionError:\n",
        "        recall_sys = 0\n",
        "\n",
        "    return recall_sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egq2eeiDEavZ"
      },
      "outputs": [],
      "source": [
        "def F1_sys(precision, recall):\n",
        "    try:\n",
        "        F1_sys = (2 * precision * recall) / (precision + recall)\n",
        "    except ZeroDivisionError:\n",
        "        F1_sys = 0\n",
        "\n",
        "    return F1_sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf-fZ5BGE3vK"
      },
      "outputs": [],
      "source": [
        "def scorer(G, Tsys):\n",
        "  \"\"\"\n",
        "  Input: a reference dataset G and an OIE system Tsys\n",
        "  Output: the precision, recall, and F1 scores of Tsys on G\n",
        "  \"\"\"\n",
        "\n",
        "  for sentence, gold_tuples in G:\n",
        "\n",
        "    pred_tuples = Tsys.extract(sentence)\n",
        "\n",
        "    # Finding the matching pairs and the unmatched tuples using the matching function\n",
        "    matching_pairs, unmatched_gold, unmatched_pred = match(gold_tuples, pred_tuples)\n",
        "\n",
        "    precision_sys = precision_sys(matching_pairs, unmatched_pred)\n",
        "    recall_sys = recall_sys(matching_pairs, unmatched_gold)\n",
        "    F1_sys = F1_sys(precision_sys, recall_sys)\n",
        "\n",
        "  # # Normalize the overall scores by dividing by the total number of tokens in G\n",
        "  # precision_sys /= total_tokens(G)\n",
        "  # recall_sys /= total_tokens(G)\n",
        "  # F1_sys /= total_tokens(G)\n",
        "\n",
        "  return precision_sys, recall_sys, F1_sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDvwdDVUE41E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70b-LYNzLHKs"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Usable for a single pair of gold and predicted tuples\n",
        "\n",
        "class Scorer:\n",
        "\n",
        "    def __init__(self, references, predictions):\n",
        "        self.references = references\n",
        "        self.predictions = predictions\n",
        "\n",
        "\n",
        "    def precision(self, t, g):\n",
        "        \"\"\"\n",
        "        t: one predicted tuple\n",
        "        g: corresponding gold tuple\n",
        "\n",
        "        returns: precision of a pair of predicted and reference tuples at the token level\n",
        "        (precision: the proportion of extracted words that are found in the reference)\n",
        "        \"\"\"\n",
        "        pred_args = t.keys()\n",
        "\n",
        "        numerator = sum(len(set(t[arg]) & set(g[arg])) for arg in pred_args)\n",
        "\n",
        "        pred_len = sum(len(t[arg]) for arg in pred_args)  # cf. The length of a tuple is the sum of lengths of its parts\n",
        "\n",
        "        precision = numerator / pred_len\n",
        "\n",
        "        return precision\n",
        "\n",
        "\n",
        "    def recall(self, t, g):\n",
        "        \"\"\"\n",
        "        t: one predicted tuple\n",
        "        g: corresponding gold tuple\n",
        "\n",
        "        returns: recall of a pair of predicted and reference tuples at the token level\n",
        "        (recall: the proportion of reference words found in the systems’ predictions)\n",
        "        \"\"\"\n",
        "        gold_args = g.keys()\n",
        "\n",
        "        numerator = sum(len(set(t[arg]) & set(g[arg])) for arg in gold_args)\n",
        "\n",
        "        gold_len = sum(len(g[arg]) for arg in gold_args)\n",
        "\n",
        "        recall = numerator / gold_len\n",
        "\n",
        "        return recall\n",
        "\n",
        "\n",
        "    def score(self):\n",
        "\n",
        "        assert len(self.predictions) == len(self.references), \"There are different numbers of reference and prediction tuples\"\n",
        "\n",
        "        precision_sys = 0\n",
        "        recall_sys = 0\n",
        "\n",
        "        for pred, ref in zip(self.predictions, self.references):\n",
        "            precision_sys += self.precision(pred, ref)\n",
        "            recall_sys += self.recall(pred, ref)\n",
        "\n",
        "        try:\n",
        "          F1_sys = (2 * precision_sys * recall_sys) / (precision_sys + recall_sys)\n",
        "        except ZeroDivisionError:\n",
        "          F1_sys = 0.0\n",
        "\n",
        "        return F1_sys\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So8QhYmoUTCO"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
